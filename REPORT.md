# Udacity DRLND Project 1 Navigation

## Learning Algorithm

The report clearly describes the learning algorithm, along with the chosen hyperparameters. It also describes the model architectures for any neural networks.

The Algorithm used in this project is based on the vanila DQN from the coding exercise. It predicts an action value from the local network based on the env and action that the agent has acted. It also coupled with the vanila experience replay, so the agent can fine the local and target network based on their experience in the memory.

## Plot of Rewards

A plot of rewards per episode is included to illustrate that the agent is able to receive an average reward (over 100 episodes) of at least +13. The submission reports the number of episodes needed to solve the environment.

![Plot of Rewards](p1_nav_score_plt_00.png)

[video link](https://youtu.be/bANBVKUrS0M)

## Ideas for Future Work

The submission has concrete future ideas for improving the agent's performance.


